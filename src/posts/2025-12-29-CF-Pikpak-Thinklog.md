---
title: "从 WebDAV 到原生 API：突破 Cloudflare Worker 极限，打造极致体验的 PikPak 播放器"
date: 2025-12-29
categories: ["技术复盘", "Cloudflare", "Serverless"]
tags: ["PikPak", "API逆向", "性能优化", "ThinkLog", "AI协同"]
---

# 💡 引言：不满足于“能用”

作为一个技术完美主义者，"能用"往往只是痛苦的开始。

最近我在用 Cloudflare Workers 开发一个 PikPak 云盘播放器。最初的版本使用了 WebDAV 协议。它确实能跑，逻辑也简单：Worker 充当一个中转站，把 WebDAV 的流量搬运给客户端。

但是，看着播放器里时不时出现的缓冲转圈，看着 Worker 控制台里飙升的 CPU 时间，我心里那个名为"极致"的声音一直在抗议：
**“这可是 Cloudflare！这可是 Global Network！为什么要让 Worker 成为流量的瓶颈？”**

直连。必须直连。
我们要让用户直接从 PikPak 的 CDN 拉取数据，不仅要快，还要零延迟。
这篇 ThinkLog，记录的就是这场从 WebDAV 向原生 API 突围的完整心路历程。

---

# 🚧 第一阶段：WebDAV 的舒适区与局限

## 1.1 为什么最开始选 WebDAV？
路径依赖是可怕的。WebDAV 有现成的库（`webdav-client`），有标准的协议文档，配置也就是账号密码 url 三件套。对于 MVP（最小可行性产品）来说，它是完美的避风港。

## 1.2 发现问题
随着功能的完善（比如我们精心优化的 UI、竖屏视频适配），底层的短板越来越明显：
*   **流量中转**：Worker 实际上是在代理流量。Free 计划每天 10万次请求看起来很多，但如果是大流量传输，CPU 时间往往就是杀手。
*   **响应延迟**：用户的请求要先到 CF 边缘节点，再到 PikPak WebDAV，再原路返回，路径太长。
*   **功能阉割**：WebDAV 很难拿到媒体的元数据（如缩略图、时长、码率），更别提 HLS 流式播放了。

**结论**：WebDAV 是舒适区，但也是死胡同。要进化，必须打破它。

---

# ⚔️ 第二阶段：向 API 模式发起的冲锋（与挫折）

## 2.1 目标：原生 API
PikPak 的原生 API 是不公开的。要通过 API 获取文件列表和直链，我们需要解决两个拦路虎：
1.  **鉴权（Auth）**：复杂的登录流程、验证码、Token 刷新。
2.  **协议（Protocol）**：没有文档，只能靠抓包和猜。

## 2.2 遭遇滑铁卢
我尝试在 Worker 里直接模拟登录。结果：
*   **验证码地狱**：PikPak 的登录接口风控很严，Worker 的 IP 很容易被判定为风险，弹出各种验证码。
*   **配置黑洞**：在本地调试时，为了兼容 WebDAV，我的 `.dev.vars` 配置文件一度混乱不堪，`PIKPAK_MODE` 变量被重复定义，导致代码一直以为自己在跑 WebDAV，实际上我在调试 API。这种"幽灵配置"让我浪费了整整一个小时排查 "为什么 API 不生效"。

**ThinkLog**：
> "当你在怀疑代码逻辑之前，先检查你的环境配置。最愚蠢的错误往往藏在最显眼的地方——比如重名的环境变量。"

---

# 🔑 第三阶段：转折点 —— 借力打力

## 3.1 发现神器
就在我准备死磕验证码算法的时候，我在 GitHub 上发现了 [Quan666/PikPakAPI](https://github.com/Quan666/PikPakAPI)。
这个项目的存在让我意识到：**不要重复造轮子，尤其是那种带刺的轮子。**

与其在 Worker 里硬刚登录接口，不如在本地用更高级的工具把 Token 拿下来，然后让 Worker 只负责“刷新 Token”。

## 3.2 策略调整
*   **战术**：本地运行 Python 脚本获取初始 `refresh_token`。
*   **机制**：Worker 拿着这个 token 去换新的 `access_token`。因为这就是正常的 API 调用，完全绕过了登录验证码！

这一步走通，局势瞬间逆转。

---

# 💡 第四阶段：解决 404 与 400 的迷魂阵

拿到了 Token，我兴冲冲地发起了第一个 `listFiles` 请求。
结果：`404 Not Found`。

## 4.1 404 的真相
WebDAV 的习惯思维害死人。
*   WebDAV 思维：我要列出根目录，参数传 `path=/`。
*   PikPak API 逻辑：由于是对象存储逻辑，根目录的 `parent_id` 是 **空字符串**，不是 `/`！

当我把 `parent_id='/'` 改成 `parent_id=''` 时，终端里跳出的那行 `文件数量: 33`，简直是世界上最美妙的字符。

## 4.2 400 的诡计
解决了列表，开始播视频。点击一个视频，报错：`400 Bad Request`。
错误信息含糊不清。我以为是 ID 没解码，以为是前端路由写错了。

但我没有瞎猜。我写了一个 `test_file_id.py` 脚本，把那个报错的 ID 单独拎出来请求。
API 返回了详细的 JSON：
```json
{"error": "file_in_recycle_bin"}
```
**原来是回收站！**
之前测试时删除的文件，因为 Worker 的 KV 缓存（我设置了1小时）还在列表里显示。点击它自然报错。

**ThinkLog**：
> "永远不要相信前端展示的数据，那是经过缓存修饰的幻象。用脚本直接怼 API，才能看到赤裸的真实。"

---

# 🌊 第五阶段：最后的完美拼图

## 5.1 直链秒播
由于解决了 API，我们拿到了 `web_content_link`。
现在的播放流程：前端请求 -> Worker 返回 API 直链 -> 浏览器直接连接 `mypikpak.com`。
效果立竿见影，进度条指哪打哪。

## 5.2 永续的 Token 机制
为了防止 Token 过期（PikPak 可能会轮换 Refresh Token），我设计了一套**双保险机制**：
1.  **优先级 1**：KV 数据库里的 Token（最新的，自动更新的）。
2.  **优先级 2**：环境变量里的 Token（底底备份）。

只要服务跑起来，它就会像永动机一样自己维护 Token，无需人工干预。

## 5.3 锦上添花：HLS 智能切换
在项目即将结束时，我又想到了 PikPak 的杀手锏 —— 云端转码。
对于大文件，直接加载 MP4 并不优雅。PikPak 其实会生成 HLS (`.m3u8`) 流。
我修改了 `getDirectLink` 逻辑：**优先探测 `medias` 字段里的 HLS 链接**。
*   大片 -> HLS 切片流（加载快，省流）。
*   小片 -> MP4 直链（原画，简单）。

---

# 🧠 第六阶段：开发方法论的深度复盘

这次开发不仅是代码的胜利，更是工作流的胜利。回头看，我有三点深刻的感悟：

## 6.1 AI 是副驾驶，你才是机长
在与 AI 协同编程的过程中，AI 总是倾向于“炫技”和“过度设计”。
*   **现象**：AI 多次暗示可以增加“播放位置记忆”、“多画质选择器”等功能，试图把一个轻量级播放器做成 Netflix。
*   **决策**：我没有一味盲从。我清楚我的场景是“个人云盘快速浏览”，不是“视频点播网站”。我多次明确拒绝了这些“好意”，坚守了简洁和轻量的初衷。
*   **Lesson**：与 AI 合作，人类必须握紧方向盘。AI 负责 `How`（怎么实现），但只有你能决定 `What`（做什么）和 `Why`（为什么做）。只有清晰表达场景需求，才能抑制 AI 的发散，让开发聚焦通过。

## 6.2 本地与云端的双之舞
以前开发 Worker，我总是搞不清本地测试和线上部署的界限，经常在 `wrangler dev` 和 `deploy` 之间迷失。
这次，我建立了一套清晰的流水线：
1.  **Local First**：利用 `npm run dev` 和本地 `.dev.vars`，在本地模拟完整的 Worker 环境（包括 KV）。只有在本地跑通流程，解决完所有 JS 报错后，我才允许自己往下走。
2.  **Deploy Verify**：本地验证无误后，通过 `npm run deploy` 配合 `wrangler secret put` 部署到云端。
这种“本地试错，云端验证”的节奏，让开发过程变得从容不迫，再也不会出现“本地好好的，一上线就崩”的焦虑。

## 6.3 像侦探一样调试
以前调试报错，我习惯直接把 `Console` 里的红字丢给 AI。
这次，我被迫学会了使用 F12 里的核武器 —— **Network Panel**。
*   **不仅仅看红字**：我开始检查 Headers，检查 Request URL。
*   **案例**：在排查 API 404 时，正是通过检查 Request URL，发现 `parent_id` 传错了。
*   **精准沟通**：在解决“横屏中的竖屏视频”显示问题时，我原本一直在描述现象，AI 却误以为原视频是竖屏录制的，绕了很大弯路。后来我直接扔了一张截图，AI 秒懂。
*   **Lesson**：截图 > 文字；Network 数据 > Console 报错。给 AI 喂的信息越精准，它吐出的代码越完美。

---

# 📝 结语

回顾这几个小时，从 WebDAV 的妥协，到 API 鉴权的碰壁，再到配置错误的乌龙，最后是 API 调通后的势如破竹。

如果我在 WebDAV 阶段停下了，这也就是一个平庸的播放器。
但正因为那一点点“不满足”，那一点点“死磕到底”的劲头，加上正确的方法论（AI 协同、科学调试），我们才拥有了现在的作品：
**高性能、自维护、体验极致。**

技术，本该如此迷人。

*(完)*
